{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settimg path for the directory\n",
    "import os\n",
    "os.chdir(\"C:/Users/Lalith/Downloads/P1 Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#loding the data sets from the directory\n",
    "filepath1='C:/Users/Lalith/Downloads/P1 Data/Consumer_Complaints_train.csv'\n",
    "pm15_train=pd.read_csv(filepath1)\n",
    "filepath2='C:/Users/Lalith/Downloads/P1 Data/Consumer_Complaints_test_share.csv'\n",
    "pm15_test=pd.read_csv(filepath2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the column name\n",
    "pm15_train=pm15_train.rename(columns={'Consumer disputed?':'consumerdisputed'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the head for train dataset\n",
    "pm15_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the head for the test data set\n",
    "pm15_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping insignificant columns, and the column which we are going to take as target\\dependent variable\n",
    "X_train=pm15_train.drop(['Complaint ID','consumerdisputed','Company','ZIP code'],axis=1)\n",
    "\n",
    "X_test=pm15_test.drop(['Complaint ID','ZIP code','Company'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking dependent variable and converting it's values into machine readble formet\n",
    "y_train=pm15_train['consumerdisputed'].map({'Yes':1,'No':0,})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing lcolumn length of the train and test data sets\n",
    "print(len(pm15_train.columns))\n",
    "print(len(pm15_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the columns present in the training set\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the training set to know the object type columns\n",
    "X_train.dtypes=='object'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the the date column  which is in object type into datetype  for training data set\n",
    "X_train['Date received']=pd.to_datetime(X_train['Date received'])\n",
    "X_train['Date sent to company']=pd.to_datetime(X_train['Date sent to company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the the date column  which is in object type into datetype  for test data set\n",
    "\n",
    "X_test['Date received']=pd.to_datetime(X_test['Date received'])\n",
    "X_test['Date sent to company']=pd.to_datetime(X_test['Date sent to company'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are taking the diference of the the two Date sent to company,Date received to train the model because individual date columns has no meaningfull insight for the ata set \n",
    "X_train['day_diff']=pd.to_numeric(X_train['Date sent to company']-X_train['Date received'])\n",
    "X_train.drop(['Date sent to company','Date received'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['day_diff']=pd.to_numeric(X_test['Date sent to company']-X_test['Date received'])\n",
    "X_test.drop(['Date sent to company','Date received'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing labelencoder to preocess the Consumer complaint narrative'\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "X_train['Consumer complaint narrative']=pd.to_numeric(X_train['Consumer complaint narrative'],errors='coerce')\n",
    "X_train['Consumer complaint narrative']=labelencoder.fit_transform(X_train['Consumer complaint narrative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test['Consumer complaint narrative']=pd.to_numeric(X_test['Consumer complaint narrative'],errors='coerce')\n",
    "X_test['Consumer complaint narrative']=labelencoder.fit_transform(X_test['Consumer complaint narrative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing training dataset head to see the alinghment\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the column length for both training and test data to ensure column length was matched\n",
    "print(X_test.shape[1])\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the traning data set into objecttype and numbertype for further processing  \n",
    "numcol=X_train.select_dtypes(include=[np.number])\n",
    "catcol=X_train.select_dtypes(include=[np.object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#spliting the test data set into objecttype and numbertype for further processing  \n",
    "\n",
    "numcol1=X_test.select_dtypes(include=[np.number])\n",
    "catcol1=X_test.select_dtypes(include=[np.object])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting dummies for the obect type columns of training data set\n",
    "catcol=pd.get_dummies(catcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting dummies for the obect type columns of test data set\n",
    "\n",
    "catcol1=pd.get_dummies(catcol1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the number type columns to normalize the data of training data set\n",
    "numcol=preprocessing.scale(numcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the number type columns to normalize the data of test data set\n",
    "\n",
    "numcol1=preprocessing.scale(numcol1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the array type numeric columns into dataframe to be concat with categorical types a\n",
    "numcol=pd.DataFrame(numcol)#training data set \n",
    "numcol1=pd.DataFrame(numcol1)#test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinating the two data frames into single dataframe to be used as X_train \n",
    "X_train=pd.concat([catcol,numcol],axis=1)#we are concating with reference to columns by taking axis=1, if 0 it will do row wise concatination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinating the two data frames into single dataframe to be used as X_test\n",
    "\n",
    "X_test=pd.concat([catcol1,numcol1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing train_test_split function to split the data sets and \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                #MODEL:1\n",
    "#importing logistic regression model and fiting the model  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the test data  \n",
    "predictions=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=clf.predict_proba(X_test)[:,1]\n",
    "print(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pridict_threshold (clf,X_test,threshold):\n",
    "    return np.where(logreg>threshold,1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thr in np.arange(0,.3,.1):\n",
    "    predictions=pridict_threshold(clf,X_test,thr)\n",
    "    print(confusion_matrix(y_test,predictions))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing metrics to find accurecy\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "AUC=roc_auc_score(y_test,predictions)\n",
    "print(AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing accurecy\n",
    "acc=accuracy_score(y_test,predictions)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.where(clf.predict(X_test)==1,\"Yes\",\"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame(list(zip(pm15_test['Complaint ID'],list(prediction))),\n",
    "                       columns=['Complaint ID','consumerdisputed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
